{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17dd4653-dd3b-430b-b3d3-f059a249c3f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Introduction\n",
    "This Jupyter notebook contains codes to implement the numerical experiments in paper (url for preprint), and is organized into four sections:\n",
    "\n",
    "- Verify convergence rate on torus\n",
    "- Persistence measure v.s. Frechet mean\n",
    "- PH approximation on massive data\n",
    "- Shape clustering\n",
    "\n",
    "The computation of persistent homology is implemented using `gudhi` (https://gudhi.inria.fr), and the computation of optimal transport is implemented using `pot` (https://pythonot.github.io).\n",
    "\n",
    "**Caveat**: The codes in general are not fast, and some can take up to 7 hours. Therefore we do not recommend the  option `Run all cells`. Instead, please run cells section by section. \n",
    "\n",
    "Author: Yueqi Cao\n",
    "\n",
    "Contact: y.cao21@imperial.ac.uk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a71b54b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-21T12:41:38.822444Z",
     "start_time": "2021-11-21T12:41:38.807467Z"
    }
   },
   "outputs": [],
   "source": [
    "# import necessary modules\n",
    "import numpy as np\n",
    "np.random.seed(20211121) # set random seed for reproducible experiments\n",
    "import ApproxPH\n",
    "import matplotlib.pyplot as plt\n",
    "from gudhi.wasserstein.barycenter import lagrangian_barycenter as bary\n",
    "\n",
    "# function to compute mean persistence measure and Frechet mean\n",
    "def compute_mean(original_set, nb_subs, nb_sub_points, max_edge_length, min_persistence, scenario):\n",
    "    subs = ApproxPH.get_subsample(original_set, nb_sub_points, nb_subs)\n",
    "    # list of PDs\n",
    "    diags = []\n",
    "    for points in subs:\n",
    "        diag = ApproxPH.get_PD(points, max_edge_length=max_edge_length, min_persistence=min_persistence)\n",
    "        diag[np.isinf(diag)] = max_edge_length\n",
    "        diags.append(diag)\n",
    "        \n",
    "    if scenario == 'mpm':\n",
    "        # compute mean persistence measure\n",
    "        sub_pers = np.array([[0,0]])\n",
    "        for diag in diags:\n",
    "            sub_pers = np.append(sub_pers, diag, axis=0)\n",
    "        unit_mass = 1/nb_subs\n",
    "        mean_mesr, mean_mesr_vis = ApproxPH.diag_to_mesr(sub_pers, unit_mass)\n",
    "        return mean_mesr, mean_mesr_vis\n",
    "    \n",
    "    if scenario == 'fm':\n",
    "        # compute Frechet mean\n",
    "        wmean, log = bary(diags, init=0, verbose=True)\n",
    "        return wmean\n",
    "    \n",
    "    if scenario == 'both':\n",
    "        # compute both mean persistence measure and Frechet mean\n",
    "        wmean, log = bary(diags, init=0, verbose=True)\n",
    "        sub_pers = np.array([[0,0]])\n",
    "        for diag in diags:\n",
    "            sub_pers = np.append(sub_pers, diag, axis=0)\n",
    "        unit_mass = 1/nb_subs\n",
    "        mean_mesr, mean_mesr_vis = ApproxPH.diag_to_mesr(sub_pers, unit_mass)\n",
    "        return mean_mesr, mean_mesr_vis, wmean    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff29826",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Verify convergence rate on torus\n",
    "\n",
    "In this section, we test the convergence rate on a synthetic data sampled from a 2-dimensional torus. \n",
    "\n",
    "State main result here:...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edcc9cdd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-21T11:03:34.656866Z",
     "start_time": "2021-11-21T10:59:53.495462Z"
    }
   },
   "outputs": [],
   "source": [
    "# generate true set and compute persistent homology\n",
    "# this step takes about 4 mins.\n",
    "X_torus = ApproxPH.sample_torus(50000, 0.8, 0.3)\n",
    "np.save('outputs/true-torus-points.npy', X_torus)\n",
    "diag_torus = ApproxPH.get_PD(X_torus, max_edge_length=0.9)\n",
    "np.save('outputs/true-torus-diagram.npy', diag_torus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b8edaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-21T11:12:00.563607Z",
     "start_time": "2021-11-21T11:11:58.322424Z"
    }
   },
   "outputs": [],
   "source": [
    "# visualize the true persistence diagram\n",
    "# use the following command if you have true-torus-diagram prepared \n",
    "# diag_torus = np.load('outputs/true-torus-diagram.npy')\n",
    "ApproxPH.plot_diag(diag_torus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32ee5a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-21T20:21:38.376485Z",
     "start_time": "2021-11-21T12:41:45.544670Z"
    }
   },
   "outputs": [],
   "source": [
    "# extract subsamples from the true set\n",
    "# use the following command if you have true-torus-points prepared\n",
    "#X_torus = np.load('outputs/true-torus-points.npy')\n",
    "# it takes about 7 hours to run 15 simulations\n",
    "nb_simulates = 15\n",
    "for i in range(nb_simulates): \n",
    "    mean_mesr, mean_mesr_vis = compute_mean(original_set = X_torus,\n",
    "                                            nb_subs = 20*(i+2),\n",
    "                                            nb_sub_points = 200*(i+2),\n",
    "                                            max_edge_length = 0.9,\n",
    "                                            min_persistence = 0.01,\n",
    "                                            scenario = 'mpm'\n",
    "                                           )\n",
    "    np.save('outputs/mean_mesr_nb%d.npy' %(i), mean_mesr)\n",
    "    print('mean persistence measure for %dth simulation' %(i))\n",
    "    # use the following command to visualize the mean persistence measure\n",
    "    # mpd.plot_mesr(mean_mesr_vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee66d291",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T08:48:51.641185Z",
     "start_time": "2021-11-22T08:48:48.325745Z"
    }
   },
   "outputs": [],
   "source": [
    "# compute Wasserstein distances between mean persistence measures and true persistence diagram\n",
    "mesr_list = []\n",
    "for i in range(15):\n",
    "    mesr = np.load('outputs/mean_mesr_nb%d.npy' %(i))\n",
    "    mesr_list.append(mesr)\n",
    "\n",
    "# load the true PD\n",
    "true_PD = np.load('outputs/true-torus-diagram.npy')\n",
    "# transform the true PD to PM\n",
    "true_mesr, true_mesr_vis = ApproxPH.diag_to_mesr(true_PD, 1)\n",
    "\n",
    "# compute the Wasserstein distance\n",
    "power_index = 3\n",
    "grid = ApproxPH.mesh_gen()\n",
    "Mp = ApproxPH.dist_mat(grid, power_index)\n",
    "dist_list = []\n",
    "point_list = []\n",
    "for i in range(len(mesr_list)):\n",
    "    distance = ApproxPH.wass_dist(mesr_list[i], true_mesr, Mp)\n",
    "    point_list.append(200*(i+2))\n",
    "    dist_list += distance.tolist()\n",
    "    \n",
    "# plot fitting curve\n",
    "ApproxPH.plot_fitting_curve(point_list, dist_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6400f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T16:15:08.256715Z",
     "start_time": "2021-11-24T16:15:08.245704Z"
    }
   },
   "source": [
    "# Comparison with the Frechet mean method\n",
    "\n",
    "In this section, we compare the performance of mean persistence measure and Frechet mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f5385a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T10:54:37.383106Z",
     "start_time": "2021-12-04T10:54:29.239344Z"
    }
   },
   "outputs": [],
   "source": [
    "# compute the true diagram\n",
    "nb_points = 5000\n",
    "true_set = ApproxPH.sample_annulus(nb_points, r1=0.2, r2=0.5)\n",
    "true_PD = ApproxPH.get_PD(true_set, max_edge_length=0.4, min_persistence=0.01)\n",
    "true_mesr, true_mesr_vis = ApproxPH.diag_to_mesr(true_PD, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3abc4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T11:03:07.021998Z",
     "start_time": "2021-12-04T11:02:52.832006Z"
    }
   },
   "outputs": [],
   "source": [
    "# each time we draw 20 subsets from the true_set\n",
    "# each subset has number of points in nb_sub_points_list\n",
    "# we compute the 2-Wasserstein distance of mean persistence measure & Frechet mean to the true diagram\n",
    "\n",
    "# set parameters\n",
    "nb_subs = 20\n",
    "unit_mass  = 1/nb_samples\n",
    "nb_sub_points_list = [50,100,150,200,250,300,350,400]\n",
    "power_index = 2\n",
    "w_list = []\n",
    "permesr_list = []\n",
    "\n",
    "for nb_sub_points in nb_sub_points_list:\n",
    "    print('number of points in each subset: %d' %(nb_sub_points))\n",
    "    mean_mesr, mean_mesr_vis, wmean = compute_mean(original_set = true_set,\n",
    "                                            nb_subs = nb_subs,\n",
    "                                            nb_sub_points = nb_sub_points,\n",
    "                                            max_edge_length = 0.4,\n",
    "                                            min_persistence = 0.01,\n",
    "                                            scenario = 'both'\n",
    "                                           )\n",
    "    wmean_mesr, wmean_mesr_vis = ApproxPH.diag_to_mesr(wmean, 1)\n",
    "    # compute distance\n",
    "    grid = ApproxPH.mesh_gen()\n",
    "    Mp = ApproxPH.dist_mat(grid, power_index)\n",
    "    permesr_distance = ApproxPH.wass_dist(mean_mesr, true_mesr, Mp)\n",
    "    wmean_distance = ApproxPH.wass_dist(wmean_mesr, true_mesr, Mp)\n",
    "    permesr_list.append(permesr_distance**(1/power_index))\n",
    "    w_list.append(wmean_distance**(1/power_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642a7b50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T11:08:40.984232Z",
     "start_time": "2021-12-04T11:08:40.862399Z"
    }
   },
   "outputs": [],
   "source": [
    "# visualize the comparison\n",
    "# plot mean persistence diagram\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.plot(nb_sub_points_list, permesr_list, linestyle='-', color='blue',\\\n",
    "         linewidth=2, label='Mean Persistence Measure')\n",
    "plt.scatter(nb_sub_points_list, permesr_list, s=70, color='red', marker='o')\n",
    "plt.plot(nb_sub_points_list, w_list, linestyle='--', color='green',\\\n",
    "         linewidth=2, label='Frechet Mean')\n",
    "plt.scatter(nb_sub_points_list, w_list, s=70, color='black', marker='P')\n",
    "plt.xlabel('Number of Points')\n",
    "plt.ylabel('2-Wasserstein distance')\n",
    "plt.title('Comparison of Frechet mean\\n and mean persistence measure')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b49b91-3513-4cff-b900-1cc863866d0f",
   "metadata": {},
   "source": [
    "# PH approximation on massive data\n",
    "\n",
    "In this section, we compute the mean persistence measure and Frechet mean for real large data\n",
    "\n",
    "description of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed431e59-8376-4a71-8fc1-f9440a9ed9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from plyfile import *\n",
    "\n",
    "pltdata = PlyData.read('grayloc.ply')\n",
    "\n",
    "x = pltdata['vertex']['x']\n",
    "y = pltdata['vertex']['y']\n",
    "z = pltdata['vertex']['z']\n",
    "\n",
    "large_points = np.array([x,y,z]).T\n",
    "print(large_points.shape)\n",
    "\n",
    "# rescale\n",
    "def rescale_points(points):\n",
    "    for i in range(3):\n",
    "        max_scale = np.max(points[:,i])\n",
    "        min_scale = np.min(points[:,i])\n",
    "        a = 2/(max_scale-min_scale)\n",
    "        b = 1 - a * max_scale\n",
    "        points[:,i] = a * points[:,i] + b\n",
    "    return points\n",
    "\n",
    "# compute persistent homology\n",
    "import ssp\n",
    "import gudhi as gd\n",
    "import matplotlib.pyplot as plt\n",
    "from gudhi.wasserstein.barycenter import lagrangian_barycenter as bary\n",
    "\n",
    "nb_samples = 30\n",
    "unit_mass  = 1/nb_samples\n",
    "nb_sub_ratio = 0.02\n",
    "power_index = 2\n",
    "max_edge_length = 0.55\n",
    "homology_dimension = 1\n",
    "\n",
    "points = rescale_points(large_points)\n",
    "nb_sub_points = int(nb_sub_ratio*large_points.shape[0])\n",
    "# get subsamples\n",
    "point_set = ssp.get_subsample(points, nb_sub_points, nb_samples)\n",
    "# get PD list\n",
    "diags = []\n",
    "for point in point_set:\n",
    "    diag = ssp.get_PD(point, homology_dimension, max_edge_length)\n",
    "    diags.append(diag)\n",
    "for diag in diags:\n",
    "    diag[np.isinf(diag)] = max_edge_length\n",
    "\n",
    "# compute wasserstein mean\n",
    "wmean, log = bary(diags, init=0, verbose=True)\n",
    "# compute mean persistence measure\n",
    "sub_pers = np.array([[0,0]])\n",
    "for diag in diags:\n",
    "    sub_pers = np.append(sub_pers, diag, axis=0)          \n",
    "grid = ssp.mesh_gen()\n",
    "Mp = ssp.dist_mat(grid, power_index)\n",
    "# diagrams to measures\n",
    "mean_mesr, mean_mesr_vis = ssp.diag_to_mesr(sub_pers, unit_mass)\n",
    "\n",
    "np.save('Fmean-1-loc.npy',wmean)\n",
    "np.save('meanM-1-loc.npy',mean_mesr_vis)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(5, 10))\n",
    "plt.rcParams.update({'font.family':'Times New Roman', 'font.size':16})\n",
    "plt.rc('text', usetex=True)\n",
    "main_ax = fig.add_subplot(211)\n",
    "main_ax.scatter(wmean[:,0], wmean[:,1], s=75, marker='o', c='red', alpha=0.8)\n",
    "main_ax.plot([0,0.2], [0,0.2], linewidth=0.5)\n",
    "main_ax.fill_between([0,0.2], [0,0.2], [0,0], facecolor='green', alpha=0.2)\t\n",
    "main_ax.set_xlim((0,0.2))\n",
    "main_ax.set_ylim((0,0.5))\n",
    "main_ax.set_xticks([0,0.1])\n",
    "main_ax.set_title(\"FM\")\n",
    "\n",
    "m_ax = fig.add_subplot(212)\n",
    "m_ax.imshow(mean_mesr_vis.T, origin='lower', cmap='hot_r', interpolation='bilinear',\\\n",
    "               aspect='auto')\n",
    "L = mean_mesr_vis.shape[0]\n",
    "m_ax.set_xlim((0,L/2))\n",
    "m_ax.set_ylim((0,L/2))\n",
    "m_ax.set_xticks([0,10,20])\n",
    "m_ax.set_xticklabels([0.0,0.2,0.4])\n",
    "m_ax.set_yticks([0,5,10,15,20,25])\n",
    "m_ax.set_yticklabels([0.0,0.1,0.2,0.3,0.4,0.5])\n",
    "m_ax.fill_between([0,L/2], [0,L/2], [0,0], facecolor='green', alpha=0.2)\n",
    "m_ax.set_title(\"MPM\")\n",
    "\n",
    "plt.savefig('1-homology.png',dpi=400)\n",
    "\n",
    "wmean=np.load('Fmean-1-loc.npy')\n",
    "mean_mesr_vis=np.load('meanM-1-loc.npy')\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "plt.rcParams.update({'font.family':'Times New Roman', 'font.size':28})\n",
    "plt.rc('text', usetex=True)\n",
    "main_ax = fig.add_subplot(111)\n",
    "main_ax.scatter(wmean[:,0], wmean[:,1], s=100, marker='o', c='red', alpha=0.8)\n",
    "main_ax.plot([0,0.2], [0,0.2], linewidth=0.5)\n",
    "main_ax.fill_between([0,0.2], [0,0.2], [0,0], facecolor='green', alpha=0.2)\t\n",
    "main_ax.set_xlim((0,0.2))\n",
    "main_ax.set_ylim((0,0.5))\n",
    "main_ax.set_xticks([0,0.1,0.2])\n",
    "plt.savefig('loc-FM-1.png',dpi=400)\n",
    "#main_ax.set_title(\"FM\")\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "plt.rcParams.update({'font.family':'Times New Roman', 'font.size':28})\n",
    "plt.rc('text', usetex=True)\n",
    "m_ax = fig.add_subplot(111)\n",
    "m_ax.imshow(mean_mesr_vis.T, origin='lower', cmap='hot_r', interpolation='bilinear',\\\n",
    "               aspect='auto')\n",
    "L = mean_mesr_vis.shape[0]\n",
    "print(L)\n",
    "m_ax.set_xlim((0,L/5))\n",
    "m_ax.set_ylim((0,L/2))\n",
    "m_ax.set_xticks([0,5,10])\n",
    "m_ax.set_xticklabels([0.0,0.1,0.2])\n",
    "m_ax.set_yticks([0,5,10,15,20,25])\n",
    "m_ax.set_yticklabels([0.0,0.1,0.2,0.3,0.4,0.5])\n",
    "m_ax.fill_between([0,L/5], [0, L/5], [0,0], facecolor='green', alpha=0.2)\n",
    "#m_ax.set_title(\"MPM\")\n",
    "plt.savefig('loc-MPM-1.png',dpi=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f154a5e1-536e-4252-9d89-16a41128dad2",
   "metadata": {},
   "source": [
    "# Shape clustering\n",
    "\n",
    "In this section, we apply subsampling methods to shape clustering.\n",
    "\n",
    "description of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6f0906-4770-479e-a074-58344ba1b863",
   "metadata": {},
   "outputs": [],
   "source": [
    "code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": true,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
